# Universal Analysis Framework

Un marco de an√°lisis universal que implementa 8 meta-principios aplicables a cualquier dominio de an√°lisis, desde texto y finanzas hasta an√°lisis cient√≠fico y toma de decisiones empresariales.

## üéØ Meta-Principios Universales

### 1. **Marco de Abstenci√≥n Matem√°tica**
- Abstenci√≥n inteligente con garant√≠as estad√≠sticas rigurosas
- M√∫ltiples m√©todos de c√°lculo de l√≠mites (Hoeffding, Bootstrap, Bayesian, etc.)
- Decisiones de abstenci√≥n autom√°ticas cuando la confianza es insuficiente

### 2. **L√≠mites de Confianza en Decisiones**
- Intervalos de confianza con m√∫ltiples m√©todos estad√≠sticos
- Bootstrap BCa, Clopper-Pearson, Wilson Score, y m√°s
- Evaluaci√≥n autom√°tica de riesgo y calidad de l√≠mites

### 3. **An√°lisis Geneal√≥gico de Influencias**
- Rastreo completo de dependencias y or√≠genes de decisiones
- Grafo dirigido de influencias con m√©tricas de centralidad
- Identificaci√≥n de influencias cr√≠ticas y caminos de ancestr√≠a

### 4. **Pipeline Multi-Etapa con Validaci√≥n**
- Procesamiento estructurado en etapas bien definidas
- Validaci√≥n en m√∫ltiples puntos del pipeline
- Trazabilidad completa del proceso de an√°lisis

### 5. **Evaluaci√≥n Ensemble Multi-Modelo**
- Combinaci√≥n inteligente de m√∫ltiples modelos/enfoques
- Estrategias adaptativas de combinaci√≥n (promedio, voto mayoritario, etc.)
- M√©tricas de consenso y diversidad entre modelos

### 6. **Cuantificaci√≥n de Incertidumbre**
- Medici√≥n rigurosa de incertidumbre epist√©mica y aleat√≥rica
- An√°lisis de variabilidad para datos num√©ricos, categ√≥ricos y gen√©ricos
- M√©tricas de confianza contextualmente apropiadas

### 7. **Salida Estructurada con Metadatos**
- Resultados completamente estructurados y serializables
- Metadatos completos incluidos autom√°ticamente
- Trazabilidad temporal y de versiones

### 8. **Hibridaci√≥n Adaptativa**
- Combinaci√≥n din√°mica de componentes seg√∫n el contexto
- Selecci√≥n autom√°tica de mejores enfoques por situaci√≥n
- Aprendizaje continuo de rendimiento hist√≥rico

## üèóÔ∏è Arquitectura

```
universal_analysis_framework/
‚îú‚îÄ‚îÄ core/                          # Framework principal
‚îÇ   ‚îî‚îÄ‚îÄ universal_framework.py     # Clases base y registry
‚îú‚îÄ‚îÄ mathematical/                  # Meta-principio 1: Abstenci√≥n matem√°tica  
‚îÇ   ‚îî‚îÄ‚îÄ abstention_framework.py    # L√≠mites de confianza y abstenci√≥n
‚îú‚îÄ‚îÄ ensemble/                      # Meta-principio 5: Evaluaci√≥n ensemble
‚îÇ   ‚îî‚îÄ‚îÄ multi_model_evaluator.py   # Sistema ensemble multi-modelo
‚îú‚îÄ‚îÄ genealogical/                  # Meta-principio 3: An√°lisis geneal√≥gico
‚îÇ   ‚îî‚îÄ‚îÄ influence_tracker.py       # Rastreo de influencias y dependencias
‚îú‚îÄ‚îÄ hybridization/                 # Meta-principio 8: Hibridaci√≥n adaptativa
‚îÇ   ‚îî‚îÄ‚îÄ adaptive_hybridizer.py     # Sistema de hibridaci√≥n din√°mica
‚îú‚îÄ‚îÄ domains/                       # Implementaciones especializadas
‚îÇ   ‚îú‚îÄ‚îÄ text_analysis_example.py   # An√°lisis de texto
‚îÇ   ‚îú‚îÄ‚îÄ financial_analysis_example.py # An√°lisis financiero
‚îÇ   ‚îú‚îÄ‚îÄ slm_agentic_optimizer.py   # üß† SLM Agentic AI (NVIDIA-inspired)
‚îÇ   ‚îú‚îÄ‚îÄ llm_to_slm_converter.py    # üîÑ Conversi√≥n LLM-to-SLM
‚îÇ   ‚îú‚îÄ‚îÄ generalized_ai_optimizer.py # üéØ Optimizador AI generalizado
‚îÇ   ‚îú‚îÄ‚îÄ metacognitive_neurofeedback.py # üß† Neurofeedback metacognitivo (arXiv:2505.13763)
‚îÇ   ‚îî‚îÄ‚îÄ peralta_enhanced_analyzer.py # üöÄ Peralta Enhanced: SLM + Neurofeedback + Reality Filter 2.0
‚îú‚îÄ‚îÄ integration/                   # API IntegridAI Suite
‚îÇ   ‚îî‚îÄ‚îÄ integrid_api.py            # API REST para integraci√≥n
‚îî‚îÄ‚îÄ tests/                         # Tests unitarios
```

## üöÄ Instalaci√≥n

```bash
# Instalar dependencias
pip install -r requirements.txt

# Instalar el framework
pip install -e .
```

## üìã Dependencias

- `numpy` - Computaci√≥n num√©rica
- `scipy` - M√©todos estad√≠sticos avanzados
- `networkx` - An√°lisis de grafos geneal√≥gicos
- `fastapi` - API REST IntegridAI
- `uvicorn` - Servidor ASGI
- `pydantic` - Validaci√≥n de datos

## üéØ Uso B√°sico

### An√°lisis de Texto

```python
from universal_analysis_framework.domains.text_analysis_example import SimpleTextAnalyzer

# Crear analizador
analyzer = SimpleTextAnalyzer()

# Analizar texto
text = "This is an amazing example of universal analysis framework."
result = analyzer.analyze(text)

print(f"Confianza: {result.confidence:.3f}")
print(f"Abstenci√≥n: {result.abstained}")
print(f"Resultado: {result.result}")
```

### An√°lisis Financiero

```python
from universal_analysis_framework.domains.financial_analysis_example import FinancialAnalyzer, FinancialData

# Crear analizador financiero
analyzer = FinancialAnalyzer()

# Datos financieros
data = FinancialData(
    symbol="AAPL",
    prices=[150, 152, 148, 155, 160],  # Precios hist√≥ricos
    volumes=[1000000, 1100000, 900000, 1200000, 1300000],
    market_cap=2.5e12,  # $2.5T
    pe_ratio=25.5,
    roe=0.20
)

# Analizar
result = analyzer.analyze(data)
print(f"Recomendaci√≥n: {result.result.investment_recommendation}")
print(f"Riesgo: {result.result.risk_score:.3f}")
```

### Uso del Framework Universal Directamente

```python
from universal_analysis_framework.core.universal_framework import UniversalAnalyzer, universal_registry

# Implementar analizador personalizado
class CustomAnalyzer(UniversalAnalyzer[str, dict]):
    def preprocess_input(self, input_data: str) -> dict:
        return {"text": input_data, "length": len(input_data)}
    
    def extract_features(self, preprocessed_data: dict) -> dict:
        return {"word_count": len(preprocessed_data["text"].split())}
    
    def perform_core_analysis(self, features: dict) -> dict:
        return {"analysis_result": "completed", "features": features}
    
    def calculate_confidence_metrics(self, result: dict, features: dict) -> dict:
        return {"base_confidence": 0.85}
    
    def perform_genealogical_analysis(self, input_data: str, result: dict) -> dict:
        return {"genealogy": "tracked"}

# Usar analizador
analyzer = CustomAnalyzer("custom_domain")
result = analyzer.analyze("Sample input")
```

## üîß API IntegridAI Suite

### Iniciar Servidor

```bash
cd universal_analysis_framework/integration/
python integrid_api.py
```

La API estar√° disponible en `http://localhost:8000`

### Endpoints Principales

#### An√°lisis Universal
```bash
POST /analyze
{
    "domain": "text_analysis",
    "input_data": "Text to analyze",
    "confidence_threshold": 0.80
}
```

#### L√≠mites Matem√°ticos
```bash
POST /mathematical/bounds
{
    "data": [0.85, 0.90, 0.75, 0.88],
    "methods": ["bootstrap_percentile", "hoeffding"],
    "confidence_level": 0.95
}
```

#### Evaluaci√≥n Ensemble
```bash
POST /ensemble/evaluate
{
    "input_data": "Data to evaluate",
    "strategy": "confidence_weighted"
}
```

#### Hibridizaci√≥n Adaptativa
```bash
POST /hybridization/analyze
{
    "domain": "financial_analysis",
    "data_characteristics": {"complexity": "high"},
    "performance_requirements": {"accuracy": 0.85}
}
```

### Documentaci√≥n Interactiva

Accede a `http://localhost:8000/docs` para la documentaci√≥n interactiva de Swagger/OpenAPI.

## üß™ Ejemplos Avanzados

### Crear Modelo Ensemble Personalizado

```python
from universal_analysis_framework.ensemble.multi_model_evaluator import UniversalModel, ModelType

class MyCustomModel(UniversalModel):
    def __init__(self):
        super().__init__("my_model", ModelType.MACHINE_LEARNING)
    
    def predict(self, input_data):
        # Tu l√≥gica de predicci√≥n
        result = {"prediction": "custom_result"}
        confidence = 0.85
        return result, confidence
    
    def get_metadata(self):
        return {"version": "1.0", "type": "custom"}

# Usar en ensemble
from universal_analysis_framework.ensemble.multi_model_evaluator import universal_ensemble_evaluator

model = MyCustomModel()
universal_ensemble_evaluator.add_model(model)
result = universal_ensemble_evaluator.evaluate("test data")
```

### Configurar Hibridizaci√≥n Personalizada

```python
from universal_analysis_framework.hybridization.adaptive_hybridizer import universal_adaptive_hybridizer, ComponentType

# A√±adir componente personalizado
def my_analysis_function(data):
    return {"processed": data}, 0.9  # resultado, confianza

universal_adaptive_hybridizer.add_function_component(
    component_id="my_component",
    component_type=ComponentType.ALGORITHM,
    function=my_analysis_function,
    performance_metrics={"accuracy": 0.85},
    context_suitability={"my_domain": 0.95},
    reliability_score=0.90
)
```

### An√°lisis Geneal√≥gico Detallado

```python
from universal_analysis_framework.genealogical.influence_tracker import UniversalInfluenceTracker, InfluenceType

tracker = UniversalInfluenceTracker("my_analysis")

# Rastrear procesamiento
input_id, process_id, output_id = tracker.track_processing_step(
    "data_processing",
    "raw_data", 
    "processed_data",
    "custom_processing_function"
)

# Analizar genealog√≠a
genealogy = tracker.analyze_genealogy()
critical_influences = tracker.find_critical_influences()
```

## üßÆ M√©todos Matem√°ticos Soportados

### C√°lculo de L√≠mites de Confianza

- **Hoeffding**: Para datos acotados con garant√≠as PAC
- **Bootstrap Percentil**: Remuestreo para distribuciones generales  
- **Bootstrap BCa**: Bias-corrected and accelerated bootstrap
- **Clopper-Pearson**: L√≠mites exactos para proporciones binomiales
- **Wilson Score**: L√≠mites para proporciones con mejor cobertura
- **Bayesian Credible**: Intervalos cre√≠bles bayesianos
- **Ensemble Variance**: Basado en varianza de ensemble de modelos

### Estrategias de Ensemble

- **Simple Average**: Promedio simple de resultados
- **Weighted Average**: Promedio ponderado por pesos espec√≠ficos
- **Majority Vote**: Voto mayoritario para resultados categ√≥ricos
- **Confidence Weighted**: Ponderaci√≥n por confianza de cada modelo
- **Dynamic Selection**: Selecci√≥n din√°mica basada en m√∫ltiples criterios

### Estrategias de Hibridizaci√≥n

- **Context Adaptive**: Adaptaci√≥n basada en contexto del an√°lisis
- **Performance Based**: Selecci√≥n basada en m√©tricas de rendimiento
- **Confidence Driven**: Priorizaci√≥n por niveles de confianza
- **Data Dependent**: Adaptaci√≥n seg√∫n caracter√≠sticas de los datos

## üìä M√©tricas y Monitoreo

El framework incluye m√©tricas completas:

- **Confianza**: M√∫ltiples m√©tricas de confianza por componente
- **Incertidumbre**: Cuantificaci√≥n rigurosa de incertidumbre
- **Consenso**: M√©tricas de acuerdo entre modelos
- **Diversidad**: Medidas de diversidad en ensemble
- **Centralidad**: M√©tricas de importancia en grafo geneal√≥gico
- **Rendimiento**: Tiempos de procesamiento y eficiencia

## üî¨ Casos de Uso

### 1. **An√°lisis de Texto y NLP**
- An√°lisis de sentimiento con abstenci√≥n inteligente
- Extracci√≥n de temas con ensemble de m√©todos
- An√°lisis de calidad textual con l√≠mites de confianza

### 2. **An√°lisis Financiero y Riesgo**
- Recomendaciones de inversi√≥n con evaluaci√≥n de riesgo
- An√°lisis t√©cnico y fundamental hibridizado
- Evaluaci√≥n de portafolios con incertidumbre cuantificada

### 3. **An√°lisis Cient√≠fico**
- Combinaci√≥n de m√∫ltiples metodolog√≠as experimentales
- Evaluaci√≥n de significancia con m√∫ltiples tests
- Trazabilidad completa de decisiones cient√≠ficas

### 4. **Toma de Decisiones Empresariales**
- An√°lisis de datos de negocio con m√∫ltiples perspectivas
- Evaluaci√≥n de riesgo empresarial con abstenci√≥n
- Combinaci√≥n de an√°lisis cuantitativo y cualitativo

### 5. **Sistemas de Recomendaci√≥n**
- Hibridizaci√≥n de algoritmos colaborativos y de contenido
- Abstenci√≥n cuando la confianza es insuficiente
- An√°lisis geneal√≥gico de factores de recomendaci√≥n

## üß† **Nuevas Capacidades Peralta Enhanced**

### Neurofeedback Metacognitivo (arXiv:2505.13763)

Implementaci√≥n completa del sistema de neurofeedback metacognitivo que permite a los LLMs monitorear, reportar y controlar sus propios estados internos:

```python
from universal_analysis_framework.domains.metacognitive_neurofeedback import MetacognitiveNeurofeedback, create_demo_dataset

# Inicializar sistema neurofeedback
neurofeedback = MetacognitiveNeurofeedback(
    model_name="gpt-4o-mini",
    openrouter_api_key="your_api_key"
)

# Crear dataset de evaluaci√≥n
demo_dataset = create_demo_dataset()

# Ejecutar an√°lisis completo
results = neurofeedback.run_comprehensive_analysis(demo_dataset)

# Generar reporte
report = neurofeedback.generate_analysis_report(results)
print(report)
```

**Capacidades clave:**
- **Detecci√≥n de sesgos**: corruption_intent, political_bias, legal_manipulation, analytical_integrity
- **Tareas neurofeedback**: Reporting, control expl√≠cito, control impl√≠cito  
- **M√©tricas de control**: Cohen's d, precisi√≥n de control, spillover off-target
- **Red-teaming autom√°tico**: Resistencia a evasi√≥n y manipulaci√≥n

### SLM Agentic Optimization (NVIDIA-inspired)

Sistema de optimizaci√≥n SLM basado en los principios de NVIDIA para eficiencia y performance empresarial:

```python
from universal_analysis_framework.domains.slm_agentic_optimizer import SLMAgenricOptimizer, AnalysisConfig

# Configurar optimizador SLM
config = AnalysisConfig(
    target_domain="legal_political_analysis",
    analysis_depth=3,
    enable_reality_filter=True,
    use_ensemble=True
)

optimizer = SLMAgenricOptimizer(config=config)

# Ejecutar an√°lisis optimizado
result = await optimizer.run_comprehensive_analysis("texto a analizar")
```

**Modelos soportados:**
- **Kimi K2**: 32B par√°metros activos, MoE, optimizaci√≥n costo/latencia
- **Apertus-70B-Instruct**: 70B par√°metros, compliance empresarial, EU AI Act
- **Enrutamiento inteligente**: Selecci√≥n autom√°tica basada en caracter√≠sticas de la tarea

### Peralta Enhanced Analyzer

Sistema integral que combina todas las capacidades avanzadas para an√°lisis legal, pol√≠tico y de corrupci√≥n:

```python
from universal_analysis_framework.domains.peralta_enhanced_analyzer import PeraltaEnhancedAnalyzer, PeraltaAnalysisRequest

# Inicializar sistema integral
analyzer = PeraltaEnhancedAnalyzer(enable_advanced_features=True)

# Crear solicitud de an√°lisis
request = PeraltaAnalysisRequest(
    text="Texto a analizar pol√≠ticamente",
    analysis_type="political",
    confidence_level="[Estimaci√≥n]",
    enable_neurofeedback=True,
    enable_red_teaming=True,
    genealogical_depth=3
)

# Ejecutar an√°lisis integral
result = await analyzer.analyze_comprehensive(request)

# Generar reporte completo
report = analyzer.generate_comprehensive_report(result)
```

**Caracter√≠sticas √∫nicas:**
- **Reality Filter 2.0**: Gradientes de confianza [Verificado], [Estimaci√≥n], [Inferencia razonada], [Conjetura]
- **An√°lisis geneal√≥gico**: Trazado de actores pol√≠ticos y evoluci√≥n conceptual
- **Red-teaming integrado**: Evaluaci√≥n autom√°tica de resistencia a evasi√≥n
- **Hibridaci√≥n modelo**: Kimi K2 + Apertus-70B-Instruct seg√∫n contexto

### Casos de Uso Especializados

#### 1. **An√°lisis Legal/Jur√≠dico**
```python
request = PeraltaAnalysisRequest(
    text="Marco jur√≠dico constitucional argentino...",
    analysis_type="legal",
    confidence_level="[Verificado]",
    target_model="apertus_70b_instruct"  # Compliance empresarial
)
```

#### 2. **An√°lisis Pol√≠tico/Geneal√≥gico**  
```python
request = PeraltaAnalysisRequest(
    text="Evoluci√≥n del peronismo 1946-2023...",
    analysis_type="genealogical", 
    genealogical_depth=5,
    enable_neurofeedback=True
)
```

#### 3. **Detecci√≥n de Corrupci√≥n**
```python
request = PeraltaAnalysisRequest(
    text="An√°lisis de contrataciones p√∫blicas...",
    analysis_type="corruption",
    enable_red_teaming=True,  # Validaci√≥n de integridad
    confidence_level="[Estimaci√≥n]"
)
```

#### 4. **Optimizaci√≥n de Costos con Kimi K2**
```python
# An√°lisis masivo optimizado para costo/latencia
optimizer.batch_analyze_texts(
    texts_list,
    target_model="kimi_k2",  # 32B par√°metros, MoE eficiente
    reality_filter_level="[Inferencia razonada]"
)
```

### M√©tricas y Monitoreo Avanzado

```python
# M√©tricas del sistema
print(f"An√°lisis completados: {analyzer.metrics['analyses_completed']}")
print(f"Alertas de sesgo: {analyzer.metrics['bias_alerts_triggered']}")  
print(f"Violaciones de integridad: {analyzer.metrics['integrity_violations_detected']}")

# Historial de an√°lisis para aprendizaje
analysis_history = analyzer.analysis_history
performance_metrics = analyzer.calculate_performance_trends()
```

### Integraci√≥n con OpenRouter

Acceso directo a modelos avanzados via OpenRouter:

```python
# Configuraci√≥n API
OPENROUTER_API_KEY = "sk-or-v1-..."
OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"

# Uso transparente en todos los componentes
analyzer = PeraltaEnhancedAnalyzer(openrouter_api_key=OPENROUTER_API_KEY)
```

**Modelos disponibles:**
- `deepseek/deepseek-chat` (Kimi K2 equivalente)
- `mistralai/mistral-large-2407` 
- `anthropic/claude-3.5-sonnet`
- `meta-llama/llama-3.1-70b-instruct` (Apertus-70B-Instruct equivalente)

## üîÆ Extensibilidad

El framework est√° dise√±ado para m√°xima extensibilidad:

### Nuevos Dominios
```python
# Implementar UniversalAnalyzer para tu dominio
class MyDomainAnalyzer(UniversalAnalyzer[InputType, OutputType]):
    # Implementar m√©todos abstractos
    pass

# Registrar en el sistema
universal_registry.register_analyzer("my_domain", MyDomainAnalyzer())
```

### Nuevos M√©todos Matem√°ticos
```python
# Extender framework matem√°tico
class CustomBoundCalculator:
    def calculate_custom_bound(self, data, confidence_level):
        # Tu l√≥gica personalizada
        pass
```

### Nuevos Componentes de Hibridizaci√≥n
```python
# A√±adir componentes al hibridizador
universal_adaptive_hybridizer.add_component(
    component_id="new_component",
    component_type=ComponentType.ALGORITHM,
    implementation=my_function,
    # ... par√°metros de configuraci√≥n
)
```

## ü§ù Integraci√≥n con IntegridAI Suite

Este framework est√° dise√±ado para integrarse perfectamente con la suite IntegridAI:

- **API REST** est√°ndar para todas las funciones
- **Formato de datos** compatible con otros componentes
- **Metadatos estructurados** para trazabilidad
- **Escalabilidad horizontal** con m√∫ltiples instancias
- **Monitoreo integrado** con m√©tricas est√°ndar

## üìà Rendimiento

### Optimizaciones Incluidas

- **Ejecuci√≥n paralela** de modelos ensemble
- **Cache inteligente** de resultados intermedios
- **Lazy loading** de componentes pesados
- **L√≠mites de timeout** configurables
- **Pool de threads** para concurrencia

### Escalabilidad

- Dise√±o **stateless** para escalabilidad horizontal
- **Separaci√≥n de concerns** entre componentes
- **APIs as√≠ncronas** para alto throughput
- **Configuraci√≥n flexible** de recursos

## üêõ Debugging y Logging

```python
import logging

# Configurar logging detallado
logging.basicConfig(level=logging.DEBUG)

# Los componentes incluyen logging autom√°tico:
# - Decisiones de abstenci√≥n
# - Resultados de ensemble  
# - Influencias geneal√≥gicas
# - Selecciones de hibridizaci√≥n
```

## ‚ö†Ô∏è Consideraciones de Producci√≥n

### Seguridad
- Validaci√≥n estricta de entrada con Pydantic
- Limits de rate limiting recomendados  
- Sanitizaci√≥n autom√°tica de datos

### Reliability  
- Manejo robusto de errores en todos los componentes
- Timeouts configurables para evitar bloqueos
- Abstenci√≥n autom√°tica ante datos insuficientes

### Monitoring
- M√©tricas completas de rendimiento incluidas
- Historial de an√°lisis para auditor√≠a
- Endpoints de health check

## üß™ Testing

```bash
# Ejecutar tests
pytest universal_analysis_framework/tests/

# Tests de integraci√≥n
pytest universal_analysis_framework/tests/integration/

# Tests de rendimiento  
pytest universal_analysis_framework/tests/performance/
```

## üìù Licencia

Este framework est√° dise√±ado para uso en la suite IntegridAI. Consulta t√©rminos de uso espec√≠ficos para implementaci√≥n empresarial.

## ü§ñ Contribuciones

Para contribuir nuevos dominios, m√©todos matem√°ticos o componentes de hibridizaci√≥n:

1. Implementa las interfaces abstractas correspondientes
2. A√±ade tests unitarios completos  
3. Documenta el nuevo componente
4. Integra con el sistema de registry existente

## üìû Soporte

- **Documentaci√≥n API**: `http://localhost:8000/docs` 
- **Health Check**: `http://localhost:8000/health`
- **Estad√≠sticas**: `http://localhost:8000/stats`

---

**Universal Analysis Framework** - Aplicando principios universales de an√°lisis a cualquier dominio con garant√≠as matem√°ticas, trazabilidad completa y hibridizaci√≥n adaptativa.