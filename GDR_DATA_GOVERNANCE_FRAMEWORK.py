"""
GDR Data Governance Framework for Private Repository
==================================================

Implements comprehensive data governance pipeline integrating GDR (Generative Data Refinement)
methodologies for enterprise-grade analytical quality assurance in private repository operations.

Key Components:
- Enterprise Data Quality Pipeline
- Automated Compliance Monitoring  
- Quality Gates and Approval Workflows
- Audit Trail and Provenance Tracking
- Performance Metrics Dashboard
- Integration with CI/CD pipelines

Author: LexCertainty Enterprise System
Version: 1.0.0 - Private Repository Integration
License: Proprietary - Enterprise Data Governance
Based on: arXiv:2509.08653 GDR principles + Enterprise best practices
"""

import os
import json
import sqlite3
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
import hashlib
import logging
import shutil
from abc import ABC, abstractmethod

from GDR_ENHANCED_UNIVERSAL_FRAMEWORK_V4 import (
    GDREnhancedUniversalFramework,
    GDRAnalysisOutput,
    GDRSafetyCriteria,
    VerificationResult,
    create_budget_analysis_gdr_config
)

class GovernanceLevel(Enum):
    """Levels of governance enforcement"""
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION = "production"
    ENTERPRISE = "enterprise"

class DataClassification(Enum):
    """Data classification levels for governance"""
    PUBLIC = "public"
    INTERNAL = "internal"
    CONFIDENTIAL = "confidential"
    RESTRICTED = "restricted"
    TOP_SECRET = "top_secret"

class QualityGate(Enum):
    """Quality gates in the governance pipeline"""
    PRE_ANALYSIS = "pre_analysis"
    POST_ANALYSIS = "post_analysis"
    PRE_PUBLICATION = "pre_publication"
    POST_PUBLICATION = "post_publication"

@dataclass
class GovernancePolicy:
    """Defines governance policies for different data types and contexts"""
    name: str
    classification_level: DataClassification
    governance_level: GovernanceLevel
    mandatory_criteria: List[GDRSafetyCriteria]
    quality_thresholds: Dict[str, float]
    approval_required: bool = True
    retention_days: int = 365
    encryption_required: bool = True
    audit_level: str = "full"

@dataclass
class QualityGateResult:
    """Result of quality gate evaluation"""
    gate: QualityGate
    passed: bool
    score: float
    issues: List[str]
    recommendations: List[str]
    timestamp: datetime
    reviewer: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class AnalysisAuditRecord:
    """Comprehensive audit record for analysis"""
    analysis_id: str
    timestamp: datetime
    user_id: str
    data_classification: DataClassification
    governance_policy: str
    input_hash: str
    output_hash: str
    gdr_output: GDRAnalysisOutput
    quality_gates: List[QualityGateResult]
    approval_status: str
    retention_until: datetime
    metadata: Dict[str, Any] = field(default_factory=dict)

class GDRDataGovernanceEngine:
    """
    Core governance engine implementing enterprise-grade data governance
    with integrated GDR quality assurance
    """
    
    def __init__(self, governance_db_path: str = "gdr_governance.db", config_path: str = "governance_config.json"):
        self.governance_db_path = governance_db_path
        self.config_path = config_path
        self.logger = logging.getLogger("GDRDataGovernanceEngine")
        
        # Initialize database
        self._initialize_database()
        
        # Load configuration
        self.policies = self._load_governance_policies()
        
        # Initialize GDR framework
        self.gdr_framework = GDREnhancedUniversalFramework(create_budget_analysis_gdr_config())
        
    def _initialize_database(self):
        """Initialize SQLite database for governance tracking"""
        
        conn = sqlite3.connect(self.governance_db_path)
        cursor = conn.cursor()
        
        # Audit records table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS audit_records (
                analysis_id TEXT PRIMARY KEY,
                timestamp TEXT NOT NULL,
                user_id TEXT NOT NULL,
                data_classification TEXT NOT NULL,
                governance_policy TEXT NOT NULL,
                input_hash TEXT NOT NULL,
                output_hash TEXT NOT NULL,
                gdr_score REAL NOT NULL,
                approval_status TEXT NOT NULL,
                retention_until TEXT NOT NULL,
                metadata TEXT
            )
        ''')
        
        # Quality gates table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS quality_gates (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                analysis_id TEXT NOT NULL,
                gate_type TEXT NOT NULL,
                passed INTEGER NOT NULL,
                score REAL NOT NULL,
                timestamp TEXT NOT NULL,
                reviewer TEXT,
                issues TEXT,
                recommendations TEXT,
                metadata TEXT,
                FOREIGN KEY (analysis_id) REFERENCES audit_records (analysis_id)
            )
        ''')
        
        # Performance metrics table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS performance_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                metric_name TEXT NOT NULL,
                metric_value REAL NOT NULL,
                analysis_id TEXT,
                metadata TEXT
            )
        ''')
        
        conn.commit()
        conn.close()
        
    def _load_governance_policies(self) -> Dict[str, GovernancePolicy]:
        """Load governance policies from configuration"""
        
        default_policies = {
            'budget_analysis_confidential': GovernancePolicy(
                name="Budget Analysis - Confidential",
                classification_level=DataClassification.CONFIDENTIAL,
                governance_level=GovernanceLevel.ENTERPRISE,
                mandatory_criteria=[
                    GDRSafetyCriteria.INFLATION_ADJUSTMENT_COMPLIANCE,
                    GDRSafetyCriteria.FACTUAL_CONSISTENCY,
                    GDRSafetyCriteria.QUANTITATIVE_PRECISION,
                    GDRSafetyCriteria.SOURCE_TRACEABILITY,
                    GDRSafetyCriteria.TEMPORAL_COHERENCE
                ],
                quality_thresholds={
                    'safety_score': 0.90,  # Higher threshold for confidential
                    'pass_rate': 0.85,
                    'source_density': 0.10
                },
                approval_required=True,
                retention_days=2555,  # 7 years
                encryption_required=True,
                audit_level="full"
            ),
            
            'general_analysis_internal': GovernancePolicy(
                name="General Analysis - Internal",
                classification_level=DataClassification.INTERNAL,
                governance_level=GovernanceLevel.PRODUCTION,
                mandatory_criteria=[
                    GDRSafetyCriteria.FACTUAL_CONSISTENCY,
                    GDRSafetyCriteria.QUANTITATIVE_PRECISION
                ],
                quality_thresholds={
                    'safety_score': 0.80,
                    'pass_rate': 0.75,
                    'source_density': 0.05
                },
                approval_required=False,
                retention_days=365,
                encryption_required=False,
                audit_level="standard"
            )
        }
        
        # Try to load from file, fallback to defaults
        try:
            if os.path.exists(self.config_path):
                with open(self.config_path, 'r') as f:
                    config_data = json.load(f)
                # TODO: Implement policy deserialization from JSON
                return default_policies
            else:
                return default_policies
        except Exception as e:
            self.logger.warning(f"Could not load governance config: {e}. Using defaults.")
            return default_policies
    
    def classify_analysis(self, analysis_context: Dict[str, Any]) -> Tuple[DataClassification, str]:
        """Classify analysis and determine appropriate governance policy"""
        
        analysis_type = analysis_context.get('analysis_type', '').lower()
        domain = analysis_context.get('domain', '').lower()
        
        # Classification rules
        if 'presupuesto' in analysis_type or 'budget' in analysis_type:
            return DataClassification.CONFIDENTIAL, 'budget_analysis_confidential'
        elif 'fiscal' in domain or 'economic' in domain:
            return DataClassification.CONFIDENTIAL, 'budget_analysis_confidential'
        else:
            return DataClassification.INTERNAL, 'general_analysis_internal'
    
    def _calculate_data_hash(self, data: Any) -> str:
        """Calculate hash for data integrity verification"""
        data_str = json.dumps(data, sort_keys=True, ensure_ascii=False)
        return hashlib.sha256(data_str.encode('utf-8')).hexdigest()
    
    def _evaluate_quality_gate(self, 
                              gate: QualityGate, 
                              gdr_output: GDRAnalysisOutput, 
                              policy: GovernancePolicy) -> QualityGateResult:
        """Evaluate specific quality gate"""
        
        issues = []
        recommendations = []
        
        if gate == QualityGate.PRE_ANALYSIS:
            # Pre-analysis checks would go here
            # For now, we'll simulate basic checks
            passed = True
            score = 1.0
            
        elif gate == QualityGate.POST_ANALYSIS:
            # Post-analysis GDR verification
            passed = gdr_output.safety_score >= policy.quality_thresholds['safety_score']
            score = gdr_output.safety_score
            
            if not passed:
                issues.append(f"Safety score {gdr_output.safety_score:.3f} below threshold {policy.quality_thresholds['safety_score']}")
                recommendations.extend(gdr_output.improvement_suggestions)
            
            # Check mandatory criteria compliance
            failed_verifications = [
                name for name, (result, message, metadata) in gdr_output.verification_results.items()
                if result == VerificationResult.FAIL
            ]
            
            if failed_verifications:
                issues.extend([f"Failed verification: {name}" for name in failed_verifications])
                
        elif gate == QualityGate.PRE_PUBLICATION:
            # Pre-publication approval checks
            passed = gdr_output.safety_score >= policy.quality_thresholds['safety_score']
            score = gdr_output.safety_score
            
            if policy.approval_required and not passed:
                issues.append("Manual approval required for publication")
                recommendations.append("Request approval from authorized reviewer")
                
        else:  # POST_PUBLICATION
            # Post-publication monitoring
            passed = True
            score = 1.0
        
        return QualityGateResult(
            gate=gate,
            passed=passed,
            score=score,
            issues=issues,
            recommendations=recommendations,
            timestamp=datetime.now()
        )
    
    def process_analysis_with_governance(self, 
                                       data_sources: Dict[str, Any],
                                       analysis_context: Dict[str, Any],
                                       analysis_function: callable,
                                       user_id: str = "system") -> Tuple[GDRAnalysisOutput, AnalysisAuditRecord]:
        """
        Process analysis through complete governance pipeline
        """
        
        self.logger.info("üèõÔ∏è Iniciando proceso de an√°lisis con gobernanza GDR...")
        
        # Step 1: Classify analysis and determine policy
        classification, policy_name = self.classify_analysis(analysis_context)
        policy = self.policies[policy_name]
        
        self.logger.info(f"üìä Clasificaci√≥n: {classification.value}, Pol√≠tica: {policy_name}")
        
        # Step 2: Generate analysis ID and hashes
        analysis_id = f"GDR_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{hashlib.md5(str(analysis_context).encode()).hexdigest()[:8]}"
        input_hash = self._calculate_data_hash(data_sources)
        
        # Step 3: Pre-analysis quality gate
        gdr_output = self.gdr_framework.analyze_with_gdr_verification(
            data_sources, analysis_context, analysis_function
        )
        
        pre_analysis_gate = self._evaluate_quality_gate(
            QualityGate.PRE_ANALYSIS, gdr_output, policy
        )
        
        # Step 4: Post-analysis quality gate
        post_analysis_gate = self._evaluate_quality_gate(
            QualityGate.POST_ANALYSIS, gdr_output, policy
        )
        
        # Step 5: Calculate output hash
        output_hash = self._calculate_data_hash(gdr_output.content)
        
        # Step 6: Create audit record
        audit_record = AnalysisAuditRecord(
            analysis_id=analysis_id,
            timestamp=datetime.now(),
            user_id=user_id,
            data_classification=classification,
            governance_policy=policy_name,
            input_hash=input_hash,
            output_hash=output_hash,
            gdr_output=gdr_output,
            quality_gates=[pre_analysis_gate, post_analysis_gate],
            approval_status="pending" if policy.approval_required and not post_analysis_gate.passed else "approved",
            retention_until=datetime.now() + timedelta(days=policy.retention_days),
            metadata={
                'framework_version': '4.0.0-GDR',
                'governance_engine_version': '1.0.0',
                'encryption_applied': policy.encryption_required
            }
        )
        
        # Step 7: Store audit record
        self._store_audit_record(audit_record)
        
        # Step 8: Record performance metrics
        self._record_performance_metrics(analysis_id, gdr_output, policy)
        
        self.logger.info(f"‚úÖ An√°lisis procesado: ID={analysis_id}, Score={gdr_output.safety_score:.3f}")
        
        return gdr_output, audit_record
    
    def _store_audit_record(self, record: AnalysisAuditRecord):
        """Store audit record in database"""
        
        conn = sqlite3.connect(self.governance_db_path)
        cursor = conn.cursor()
        
        # Store main audit record
        cursor.execute('''
            INSERT INTO audit_records 
            (analysis_id, timestamp, user_id, data_classification, governance_policy,
             input_hash, output_hash, gdr_score, approval_status, retention_until, metadata)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            record.analysis_id,
            record.timestamp.isoformat(),
            record.user_id,
            record.data_classification.value,
            record.governance_policy,
            record.input_hash,
            record.output_hash,
            record.gdr_output.safety_score,
            record.approval_status,
            record.retention_until.isoformat(),
            json.dumps(record.metadata)
        ))
        
        # Store quality gate results
        for gate_result in record.quality_gates:
            cursor.execute('''
                INSERT INTO quality_gates
                (analysis_id, gate_type, passed, score, timestamp, reviewer, issues, recommendations, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                record.analysis_id,
                gate_result.gate.value,
                1 if gate_result.passed else 0,
                gate_result.score,
                gate_result.timestamp.isoformat(),
                gate_result.reviewer,
                json.dumps(gate_result.issues),
                json.dumps(gate_result.recommendations),
                json.dumps(gate_result.metadata)
            ))
        
        conn.commit()
        conn.close()
    
    def _record_performance_metrics(self, analysis_id: str, gdr_output: GDRAnalysisOutput, policy: GovernancePolicy):
        """Record performance metrics for monitoring"""
        
        conn = sqlite3.connect(self.governance_db_path)
        cursor = conn.cursor()
        
        timestamp = datetime.now().isoformat()
        
        # Record key metrics
        metrics = [
            ('gdr_safety_score', gdr_output.safety_score),
            ('pass_rate', gdr_output.quality_metrics.get('pass_rate', 0.0)),
            ('source_density', gdr_output.quality_metrics.get('source_density', 0.0)),
            ('content_length', gdr_output.quality_metrics.get('content_length', 0.0)),
            ('policy_compliance', 1.0 if gdr_output.safety_score >= policy.quality_thresholds['safety_score'] else 0.0)
        ]
        
        for metric_name, metric_value in metrics:
            cursor.execute('''
                INSERT INTO performance_metrics (timestamp, metric_name, metric_value, analysis_id, metadata)
                VALUES (?, ?, ?, ?, ?)
            ''', (
                timestamp,
                metric_name,
                metric_value,
                analysis_id,
                json.dumps({'policy': policy.name})
            ))
        
        conn.commit()
        conn.close()
    
    def generate_compliance_dashboard(self, days_back: int = 30) -> Dict[str, Any]:
        """Generate compliance dashboard data"""
        
        conn = sqlite3.connect(self.governance_db_path)
        cursor = conn.cursor()
        
        cutoff_date = (datetime.now() - timedelta(days=days_back)).isoformat()
        
        # Overall compliance rate
        cursor.execute('''
            SELECT 
                COUNT(*) as total_analyses,
                SUM(CASE WHEN approval_status = 'approved' THEN 1 ELSE 0 END) as approved_analyses,
                AVG(gdr_score) as avg_gdr_score
            FROM audit_records 
            WHERE timestamp >= ?
        ''', (cutoff_date,))
        
        overall_stats = cursor.fetchone()
        
        # Compliance by policy
        cursor.execute('''
            SELECT 
                governance_policy,
                COUNT(*) as count,
                AVG(gdr_score) as avg_score,
                SUM(CASE WHEN approval_status = 'approved' THEN 1 ELSE 0 END) as approved
            FROM audit_records 
            WHERE timestamp >= ?
            GROUP BY governance_policy
        ''', (cutoff_date,))
        
        policy_stats = cursor.fetchall()
        
        # Performance trends
        cursor.execute('''
            SELECT 
                DATE(timestamp) as date,
                AVG(metric_value) as avg_value
            FROM performance_metrics 
            WHERE metric_name = 'gdr_safety_score' AND timestamp >= ?
            GROUP BY DATE(timestamp)
            ORDER BY date
        ''', (cutoff_date,))
        
        performance_trend = cursor.fetchall()
        
        conn.close()
        
        return {
            'period_days': days_back,
            'overall_stats': {
                'total_analyses': overall_stats[0] or 0,
                'approved_analyses': overall_stats[1] or 0,
                'compliance_rate': (overall_stats[1] or 0) / max(overall_stats[0] or 1, 1),
                'avg_gdr_score': overall_stats[2] or 0.0
            },
            'policy_breakdown': [
                {
                    'policy': row[0],
                    'count': row[1],
                    'avg_score': row[2],
                    'approved': row[3],
                    'approval_rate': row[3] / max(row[1], 1)
                }
                for row in policy_stats
            ],
            'performance_trend': [
                {'date': row[0], 'avg_gdr_score': row[1]}
                for row in performance_trend
            ]
        }
    
    def cleanup_expired_records(self):
        """Clean up expired records according to retention policies"""
        
        conn = sqlite3.connect(self.governance_db_path)
        cursor = conn.cursor()
        
        current_time = datetime.now().isoformat()
        
        # Find expired records
        cursor.execute('''
            SELECT analysis_id FROM audit_records WHERE retention_until < ?
        ''', (current_time,))
        
        expired_ids = [row[0] for row in cursor.fetchall()]
        
        if expired_ids:
            # Delete quality gates for expired analyses
            placeholders = ','.join('?' for _ in expired_ids)
            cursor.execute(f'''
                DELETE FROM quality_gates WHERE analysis_id IN ({placeholders})
            ''', expired_ids)
            
            # Delete performance metrics for expired analyses
            cursor.execute(f'''
                DELETE FROM performance_metrics WHERE analysis_id IN ({placeholders})
            ''', expired_ids)
            
            # Delete audit records
            cursor.execute(f'''
                DELETE FROM audit_records WHERE analysis_id IN ({placeholders})
            ''', expired_ids)
            
            conn.commit()
            self.logger.info(f"üóëÔ∏è Cleaned up {len(expired_ids)} expired records")
        
        conn.close()
        return len(expired_ids)

# Utility functions for governance framework integration

def setup_enterprise_governance(base_path: str = "./governance") -> GDRDataGovernanceEngine:
    """Setup enterprise governance environment"""
    
    # Create governance directory structure
    governance_path = Path(base_path)
    governance_path.mkdir(exist_ok=True)
    
    (governance_path / "audit_logs").mkdir(exist_ok=True)
    (governance_path / "compliance_reports").mkdir(exist_ok=True)
    (governance_path / "policies").mkdir(exist_ok=True)
    
    # Initialize governance engine
    db_path = governance_path / "gdr_governance.db"
    config_path = governance_path / "governance_config.json"
    
    engine = GDRDataGovernanceEngine(str(db_path), str(config_path))
    
    return engine

def generate_governance_report(engine: GDRDataGovernanceEngine, output_path: str = "governance_report.md") -> str:
    """Generate comprehensive governance report"""
    
    dashboard_data = engine.generate_compliance_dashboard()
    
    report = []
    report.append("# GDR Data Governance Compliance Report")
    report.append("=" * 50)
    report.append(f"**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append(f"**Period**: Last {dashboard_data['period_days']} days")
    report.append("")
    
    # Overall statistics
    overall = dashboard_data['overall_stats']
    report.append("## Overall Compliance Statistics")
    report.append("-" * 30)
    report.append(f"- **Total Analyses**: {overall['total_analyses']}")
    report.append(f"- **Approved Analyses**: {overall['approved_analyses']}")
    report.append(f"- **Compliance Rate**: {overall['compliance_rate']:.1%}")
    report.append(f"- **Average GDR Score**: {overall['avg_gdr_score']:.3f}")
    report.append("")
    
    # Policy breakdown
    report.append("## Policy-Level Breakdown")
    report.append("-" * 25)
    for policy in dashboard_data['policy_breakdown']:
        report.append(f"### {policy['policy']}")
        report.append(f"- Analyses: {policy['count']}")
        report.append(f"- Avg Score: {policy['avg_score']:.3f}")
        report.append(f"- Approval Rate: {policy['approval_rate']:.1%}")
        report.append("")
    
    # Performance trend
    if dashboard_data['performance_trend']:
        report.append("## Performance Trend")
        report.append("-" * 18)
        report.append("| Date | Avg GDR Score |")
        report.append("|------|---------------|")
        for trend in dashboard_data['performance_trend'][-10:]:  # Last 10 days
            report.append(f"| {trend['date']} | {trend['avg_gdr_score']:.3f} |")
        report.append("")
    
    report_content = "\n".join(report)
    
    # Save report
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    return report_content

# Example usage and testing
if __name__ == "__main__":
    print("üèõÔ∏è Testing GDR Data Governance Framework...")
    
    # Setup governance engine
    engine = setup_enterprise_governance()
    
    # Test analysis with governance
    test_data = {
        'presupuesto_2026': 'Gastos: $158,865 millones vs 2025: $180,637 millones'
    }
    
    test_context = {
        'analysis_type': 'presupuesto_nacional',
        'domain': 'fiscal_policy'
    }
    
    def test_analysis(data, context):
        return {
            'result': 'Reducci√≥n nominal del 12.1%',
            'methodology': 'GDR Enhanced Framework'
        }
    
    try:
        gdr_output, audit_record = engine.process_analysis_with_governance(
            test_data, test_context, test_analysis
        )
        
        print(f"‚úÖ Analysis processed: ID={audit_record.analysis_id}")
        print(f"üìä GDR Score: {gdr_output.safety_score:.3f}")
        print(f"üèõÔ∏è Governance Status: {audit_record.approval_status}")
        
        # Generate compliance report
        report = generate_governance_report(engine)
        print("üìã Governance report generated")
        
    except Exception as e:
        print(f"‚ùå Error: {e}")